{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import imageio\n",
    "import cv2\n",
    "import os\n",
    "# import PIL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torchvision import datasets\n",
    "# from torchvision import transforms\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        img = cv2.imread(filepath)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "X = load_images_from_directory('./Train/low')\n",
    "y = load_images_from_directory('./Train/high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485, 400, 600, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X/255\n",
    "y = y/255\n",
    "\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01568627, 0.01960784, 0.02352941],\n",
       "         [0.01568627, 0.01960784, 0.03921569],\n",
       "         [0.01960784, 0.02745098, 0.01960784],\n",
       "         ...,\n",
       "         [0.04705882, 0.05490196, 0.05490196],\n",
       "         [0.05098039, 0.05098039, 0.05490196],\n",
       "         [0.05490196, 0.05490196, 0.05490196]],\n",
       "\n",
       "        [[0.00392157, 0.01960784, 0.01176471],\n",
       "         [0.00784314, 0.01960784, 0.01960784],\n",
       "         [0.00784314, 0.01568627, 0.00784314],\n",
       "         ...,\n",
       "         [0.05098039, 0.05098039, 0.05882353],\n",
       "         [0.05490196, 0.05882353, 0.04705882],\n",
       "         [0.04313725, 0.05882353, 0.05490196]],\n",
       "\n",
       "        [[0.01176471, 0.01176471, 0.01568627],\n",
       "         [0.02352941, 0.01960784, 0.01568627],\n",
       "         [0.01960784, 0.02352941, 0.01176471],\n",
       "         ...,\n",
       "         [0.0627451 , 0.05882353, 0.05882353],\n",
       "         [0.05490196, 0.05098039, 0.03921569],\n",
       "         [0.05098039, 0.0627451 , 0.07058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01568627, 0.02352941, 0.01960784],\n",
       "         [0.00784314, 0.01568627, 0.00784314],\n",
       "         [0.01176471, 0.01960784, 0.00784314],\n",
       "         ...,\n",
       "         [0.09803922, 0.08627451, 0.07843137],\n",
       "         [0.09019608, 0.08235294, 0.0627451 ],\n",
       "         [0.09803922, 0.09411765, 0.09019608]],\n",
       "\n",
       "        [[0.01960784, 0.01960784, 0.        ],\n",
       "         [0.01960784, 0.01960784, 0.01568627],\n",
       "         [0.01568627, 0.01176471, 0.00784314],\n",
       "         ...,\n",
       "         [0.09019608, 0.09019608, 0.08235294],\n",
       "         [0.09411765, 0.08627451, 0.0745098 ],\n",
       "         [0.09411765, 0.08235294, 0.07058824]],\n",
       "\n",
       "        [[0.00392157, 0.02352941, 0.01568627],\n",
       "         [0.        , 0.01960784, 0.01176471],\n",
       "         [0.02352941, 0.01568627, 0.01176471],\n",
       "         ...,\n",
       "         [0.09411765, 0.08235294, 0.0745098 ],\n",
       "         [0.09411765, 0.09019608, 0.07843137],\n",
       "         [0.09411765, 0.08235294, 0.0745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.01176471, 0.00392157],\n",
       "         [0.00392157, 0.01176471, 0.00392157],\n",
       "         [0.        , 0.00784314, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.00784314, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.00784314, 0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.00392157, 0.00784314, 0.00392157],\n",
       "         [0.00784314, 0.00392157, 0.        ],\n",
       "         [0.00392157, 0.00784314, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.00784314, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.00784314, 0.00392157, 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.01176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157, 0.01568627, 0.00392157],\n",
       "         [0.00784314, 0.00784314, 0.01176471],\n",
       "         [0.00392157, 0.00784314, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.01176471, 0.        ],\n",
       "         [0.00784314, 0.01960784, 0.00392157],\n",
       "         [0.        , 0.01568627, 0.00784314]],\n",
       "\n",
       "        [[0.01176471, 0.00784314, 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.01176471],\n",
       "         [0.        , 0.00784314, 0.00784314],\n",
       "         ...,\n",
       "         [0.00392157, 0.01176471, 0.01176471],\n",
       "         [0.00392157, 0.01176471, 0.        ],\n",
       "         [0.        , 0.01176471, 0.00392157]],\n",
       "\n",
       "        [[0.        , 0.01176471, 0.        ],\n",
       "         [0.00392157, 0.01568627, 0.01176471],\n",
       "         [0.00392157, 0.00784314, 0.01176471],\n",
       "         ...,\n",
       "         [0.01568627, 0.01176471, 0.00392157],\n",
       "         [0.        , 0.00784314, 0.        ],\n",
       "         [0.01176471, 0.01176471, 0.00784314]]],\n",
       "\n",
       "\n",
       "       [[[0.09803922, 0.09411765, 0.10980392],\n",
       "         [0.10196078, 0.09411765, 0.10980392],\n",
       "         [0.10196078, 0.09803922, 0.09803922],\n",
       "         ...,\n",
       "         [0.01176471, 0.00784314, 0.02352941],\n",
       "         [0.01176471, 0.00784314, 0.01568627],\n",
       "         [0.01960784, 0.03137255, 0.05490196]],\n",
       "\n",
       "        [[0.09803922, 0.09803922, 0.09803922],\n",
       "         [0.09803922, 0.09019608, 0.11372549],\n",
       "         [0.10588235, 0.09411765, 0.11372549],\n",
       "         ...,\n",
       "         [0.        , 0.00784314, 0.02352941],\n",
       "         [0.01176471, 0.01176471, 0.02745098],\n",
       "         [0.03529412, 0.02745098, 0.05882353]],\n",
       "\n",
       "        [[0.10980392, 0.09411765, 0.10980392],\n",
       "         [0.10196078, 0.09019608, 0.09411765],\n",
       "         [0.10196078, 0.09803922, 0.10588235],\n",
       "         ...,\n",
       "         [0.00784314, 0.01568627, 0.01568627],\n",
       "         [0.00784314, 0.01176471, 0.01960784],\n",
       "         [0.03529412, 0.03137255, 0.05098039]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.01176471, 0.02352941],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.01176471, 0.01568627, 0.02352941],\n",
       "         ...,\n",
       "         [0.00784314, 0.00392157, 0.01960784],\n",
       "         [0.00392157, 0.00392157, 0.01960784],\n",
       "         [0.00392157, 0.        , 0.01568627]],\n",
       "\n",
       "        [[0.01960784, 0.01568627, 0.02352941],\n",
       "         [0.03137255, 0.01568627, 0.02745098],\n",
       "         [0.01568627, 0.01176471, 0.01176471],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.01960784],\n",
       "         [0.00784314, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.00392157, 0.03921569]],\n",
       "\n",
       "        [[0.03921569, 0.03137255, 0.05882353],\n",
       "         [0.03921569, 0.03137255, 0.0627451 ],\n",
       "         [0.04705882, 0.03921569, 0.04313725],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.01568627],\n",
       "         [0.00392157, 0.00784314, 0.01568627],\n",
       "         [0.        , 0.00784314, 0.01568627]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.01176471],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.00392157, 0.        ],\n",
       "         [0.01568627, 0.00392157, 0.        ],\n",
       "         [0.01568627, 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.01176471],\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.        , 0.        ],\n",
       "         [0.01176471, 0.00392157, 0.        ],\n",
       "         [0.00784314, 0.        , 0.00392157],\n",
       "         ...,\n",
       "         [0.00784314, 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00784314],\n",
       "         [0.00392157, 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00784314, 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.        ],\n",
       "         [0.01176471, 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00784314, 0.        , 0.01176471]],\n",
       "\n",
       "        [[0.00392157, 0.        , 0.        ],\n",
       "         [0.        , 0.00392157, 0.00392157],\n",
       "         [0.01960784, 0.        , 0.00392157],\n",
       "         ...,\n",
       "         [0.00784314, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.00784314, 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.        , 0.        ],\n",
       "         [0.00784314, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.01176471, 0.00392157, 0.00392157],\n",
       "         [0.00784314, 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.01568627, 0.00392157, 0.01176471],\n",
       "         [0.        , 0.00784314, 0.01960784],\n",
       "         [0.        , 0.00392157, 0.01176471],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.00784314]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.01176471, 0.00392157],\n",
       "         [0.00784314, 0.00784314, 0.02352941],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.00392157, 0.00392157]],\n",
       "\n",
       "        [[0.        , 0.00392157, 0.01568627],\n",
       "         [0.00392157, 0.00392157, 0.01176471],\n",
       "         [0.        , 0.00392157, 0.01568627],\n",
       "         ...,\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.00392157, 0.00784314],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.00784314, 0.00392157],\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.00392157, 0.01960784],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.01568627],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.01176471],\n",
       "         [0.        , 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.        , 0.01176471],\n",
       "         [0.00784314, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.00392157],\n",
       "         [0.        , 0.00392157, 0.00784314],\n",
       "         [0.00392157, 0.        , 0.01176471]]],\n",
       "\n",
       "\n",
       "       [[[0.01568627, 0.01176471, 0.00784314],\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.00784314, 0.00784314, 0.01176471],\n",
       "         [0.        , 0.00784314, 0.01568627]],\n",
       "\n",
       "        [[0.        , 0.00392157, 0.01176471],\n",
       "         [0.        , 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.01176471],\n",
       "         ...,\n",
       "         [0.00784314, 0.01176471, 0.01176471],\n",
       "         [0.        , 0.        , 0.00784314],\n",
       "         [0.        , 0.00392157, 0.01568627]],\n",
       "\n",
       "        [[0.        , 0.00784314, 0.01176471],\n",
       "         [0.00392157, 0.00784314, 0.02352941],\n",
       "         [0.00392157, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.01176471, 0.02352941],\n",
       "         [0.        , 0.00392157, 0.01568627],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01176471, 0.00392157, 0.01568627],\n",
       "         [0.00784314, 0.00784314, 0.01176471],\n",
       "         [0.00392157, 0.00784314, 0.01568627],\n",
       "         ...,\n",
       "         [0.00392157, 0.00784314, 0.01960784],\n",
       "         [0.00392157, 0.00784314, 0.01176471],\n",
       "         [0.00784314, 0.00784314, 0.00784314]],\n",
       "\n",
       "        [[0.00784314, 0.01176471, 0.00392157],\n",
       "         [0.00784314, 0.00392157, 0.00784314],\n",
       "         [0.01568627, 0.00784314, 0.02352941],\n",
       "         ...,\n",
       "         [0.00392157, 0.00784314, 0.00784314],\n",
       "         [0.01568627, 0.00784314, 0.01176471],\n",
       "         [0.01176471, 0.00784314, 0.02352941]],\n",
       "\n",
       "        [[0.00392157, 0.        , 0.00784314],\n",
       "         [0.00392157, 0.00784314, 0.00784314],\n",
       "         [0.        , 0.01176471, 0.01960784],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.02352941],\n",
       "         [0.        , 0.01176471, 0.01176471],\n",
       "         [0.        , 0.01176471, 0.01176471]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.transpose(0, 3, 1, 2)\n",
    "X = torch.tensor(X, dtype=torch.float32).cuda()\n",
    "y = y.transpose(0, 3, 1, 2)\n",
    "y = torch.tensor(y, dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)#, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "combined_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, filters, kernel_size=3, padding=1)\n",
    "        self.sp = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.sp(out)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(filters, filters, kernel_size=3, padding=1)\n",
    "        self.sp1 = nn.Softplus()\n",
    "        self.sp2 = nn.Softplus()\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.sp1(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual  \n",
    "        out = self.sp2(out)\n",
    "        return out\n",
    "\n",
    "class CAM(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(CAM, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // 16, 1, bias=False),\n",
    "            nn.Softplus(),\n",
    "            nn.Conv2d(channels // 16, channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.global_avg_pool(x)\n",
    "        y = self.fc(y)\n",
    "        return x * y\n",
    "\n",
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, pool_size, output_size):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(pool_size)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        pooled = self.pool(x)\n",
    "        upsampled = F.interpolate(pooled, size=self.output_size, mode='bilinear', align_corners=True)\n",
    "        return upsampled\n",
    "\n",
    "class KSM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KSM, self).__init__()\n",
    "        self.conv = nn.Conv2d(36, 3, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_block1 = CNNBlock(filters=32)\n",
    "        self.residual_block = ResidualBlock(filters=32)\n",
    "        self.cam = CAM(channels=32)\n",
    "        self.conv2 = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "        self.pyramid1 = PyramidPooling(pool_size=1, output_size=(400, 600))\n",
    "        self.pyramid2 = PyramidPooling(pool_size=2, output_size=(400, 600))\n",
    "        self.pyramid3 = PyramidPooling(pool_size=4, output_size=(400, 600))\n",
    "        self.pyramid4 = PyramidPooling(pool_size=8, output_size=(400, 600))\n",
    "        self.pyramid5 = PyramidPooling(pool_size=16, output_size=(400, 600))\n",
    "        self.ksm = KSM()\n",
    "        self.final_conv = nn.Conv2d(3, 3, kernel_size=1, padding=0)\n",
    "        self.sp = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.conv_block1(x)\n",
    "        C1 = self.residual_block(C1) \n",
    "        cam = self.cam(C1)\n",
    "        C2 = self.sp(self.conv2(cam))\n",
    "        concat1 = torch.cat([C2, x], dim=1)  \n",
    "\n",
    "        p1 = self.pyramid1(concat1)\n",
    "        p2 = self.pyramid2(concat1)\n",
    "        p3 = self.pyramid3(concat1)\n",
    "        p4 = self.pyramid4(concat1)\n",
    "        p5 = self.pyramid5(concat1)\n",
    "\n",
    "        concat2 = torch.cat([p1, p2, p3, p4, p5, concat1], dim=1) \n",
    "\n",
    "        ksm = self.ksm(concat2)\n",
    "        out = self.final_conv(ksm)\n",
    "        return out\n",
    "\n",
    "    \n",
    "model = Net().cuda()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_block1): CNNBlock(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sp): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (residual_block): ResidualBlock(\n",
       "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sp1): Softplus(beta=1, threshold=20)\n",
       "    (sp2): Softplus(beta=1, threshold=20)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (cam): CAM(\n",
       "    (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "      (2): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pyramid1): PyramidPooling(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (pyramid2): PyramidPooling(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=2)\n",
       "  )\n",
       "  (pyramid3): PyramidPooling(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=4)\n",
       "  )\n",
       "  (pyramid4): PyramidPooling(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=8)\n",
       "  )\n",
       "  (pyramid5): PyramidPooling(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=16)\n",
       "  )\n",
       "  (ksm): KSM(\n",
       "    (conv): Conv2d(36, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (final_conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (sp): Softplus(beta=1, threshold=20)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./nnweights3.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (images, y_batched) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        y_batched = y_batched.cuda()\n",
    "        recon_images = model(images)\n",
    "        loss = criterion(recon_images, y_batched)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "combined_dataset_test = TensorDataset(X_test, y_test)\n",
    "testing_loader = DataLoader(combined_dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_psnr = 0.0\n",
    "num_batches = len(testing_loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testing_loader:\n",
    "        reconstructed_images = model(images)\n",
    "        mse = nn.MSELoss(reduction='mean')(reconstructed_images, labels)\n",
    "        psnr = 10 * torch.log10(1.0 / mse)\n",
    "        total_psnr += psnr.item()\n",
    "\n",
    "average_psnr = total_psnr / num_batches\n",
    "print(f\"Average PSNR on testing data: {average_psnr:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0058,  0.0960,  0.1520,  ...,  0.1294,  0.0022, -0.5081],\n",
       "          [-0.1771, -0.3156, -0.4596,  ..., -0.4916, -0.4431, -0.8113],\n",
       "          [-0.2581, -0.4313, -0.4828,  ..., -0.4156, -0.2678, -0.6241],\n",
       "          ...,\n",
       "          [-0.2992, -0.5388, -0.6537,  ..., -0.5485, -0.3424, -0.6676],\n",
       "          [-0.3849, -0.6233, -0.8326,  ..., -0.7141, -0.4129, -0.7493],\n",
       "          [-0.8647, -1.0609, -1.1479,  ..., -1.1159, -0.9239, -1.0833]],\n",
       "\n",
       "         [[ 0.8457,  1.0505,  1.1235,  ...,  1.1058,  0.9501,  0.3180],\n",
       "          [ 0.7120,  0.5600,  0.3822,  ...,  0.3571,  0.4119, -0.0416],\n",
       "          [ 0.6137,  0.4117,  0.3499,  ...,  0.4494,  0.6263,  0.1927],\n",
       "          ...,\n",
       "          [ 0.5550,  0.2739,  0.1279,  ...,  0.2568,  0.5116,  0.1103],\n",
       "          [ 0.4392,  0.1695, -0.0946,  ...,  0.0482,  0.4176,  0.0082],\n",
       "          [-0.1599, -0.3893, -0.4876,  ..., -0.4480, -0.2136, -0.4106]],\n",
       "\n",
       "         [[ 1.7732,  2.1121,  2.2089,  ...,  2.1945,  1.9983,  1.1914],\n",
       "          [ 1.6806,  1.5047,  1.2785,  ...,  1.2592,  1.3237,  0.7484],\n",
       "          [ 1.5570,  1.3110,  1.2343,  ...,  1.3753,  1.5950,  1.0490],\n",
       "          ...,\n",
       "          [ 1.4740,  1.1295,  0.9401,  ...,  1.1053,  1.4297,  0.9193],\n",
       "          [ 1.3173,  0.9968,  0.6561,  ...,  0.8361,  1.3041,  0.7887],\n",
       "          [ 0.5486,  0.2695,  0.1527,  ...,  0.2051,  0.5009,  0.2496]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
